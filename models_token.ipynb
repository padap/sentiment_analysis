{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Основы слов, в качестве признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.tokenize as word_tokenize\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"russian\") # Choose a language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re \n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбивка на выборку (кросс валидация)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from get_fold import get_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrainTest(seed = 42):\n",
    "    X_train = pd.concat([get_fold(K_fold=i,seed = seed) for i in range(7)])\n",
    "    X_test  = pd.concat([get_fold(K_fold=i,seed = seed) for i in range(7,10)])\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics = ['accuracy_score', 'f1_score', 'precision_score', 'recall_score']\n",
    "types =   ['0/1/-1', '0/1,-1','1/0,-1','-1/0,1']\n",
    "\n",
    "def make_log(y_predict, y_test, seed = 42):\n",
    "    text =  \"\\n\\nseed\\t\"+str(seed)\n",
    "    text += \"\\n'3 class classification\\t0/1/-1\"\n",
    "    text += \"\\naccuracy_score\\t\"+str(accuracy_score(y_test, y_predict))\n",
    "    text += \"\\nf1_score\\t\"+str(f1_score(y_test, y_predict, average = 'micro'))\n",
    "    text += \"\\nprecision_score\\t\"+str(precision_score(y_test, y_predict, average = 'micro'))\n",
    "    text += \"\\nrecall_score\\t\"+str(recall_score(y_test, y_predict, average = 'micro'))\n",
    "    \n",
    "    text += \"\\n2 class classification\\t0/1,-1\"\n",
    "    lbl = 0\n",
    "    text += \"\\naccuracy_score\\t\"+str(accuracy_score([i==lbl for i in  y_test], [i==lbl for i in  y_predict]))\n",
    "    text += \"\\nf1_score\\t\"+str(f1_score([i==lbl for i in  y_test], [i==lbl for i in  y_predict]))\n",
    "    text += \"\\nprecision_score\\t\"+str(precision_score([i==lbl for i in  y_test], [i==lbl for i in  y_predict]))\n",
    "    text += \"\\nrecall_score\\t\"+str(recall_score([i==lbl for i in  y_test], [i==lbl for i in  y_predict]))\n",
    "\n",
    "    \n",
    "    text += \"\\n2 class classification\\t1/0,-1\"\n",
    "    lbl = 1\n",
    "    text += \"\\naccuracy_score\\t\"+str(accuracy_score([i==lbl for i in  y_test], [i==lbl for i in  y_predict]))\n",
    "    text += \"\\nf1_score\\t\"+str(f1_score([i==lbl for i in  y_test], [i==lbl for i in  y_predict]))\n",
    "    text += \"\\nprecision_score\\t\"+str(precision_score([i==lbl for i in  y_test], [i==lbl for i in  y_predict]))\n",
    "    text += \"\\nrecall_score\\t\"+str(recall_score([i==lbl for i in  y_test], [i==lbl for i in  y_predict]))\n",
    "\n",
    "    text += \"\\n2 class classification\\t-1/0,1\"\n",
    "    lbl = -1\n",
    "    text += \"\\naccuracy_score\\t\"+str(accuracy_score([i==lbl for i in  y_test], [i==lbl for i in  y_predict]))\n",
    "    text += \"\\nf1_score\\t\"+str(f1_score([i==lbl for i in  y_test], [i==lbl for i in  y_predict]))\n",
    "    text += \"\\nprecision_score\\t\"+str(precision_score([i==lbl for i in  y_test], [i==lbl for i in  y_predict]))\n",
    "    text += \"\\nrecall_score\\t\"+str(recall_score([i==lbl for i in  y_test], [i==lbl for i in  y_predict]))\n",
    "   \n",
    "    text += \"\\nmatrix_cross_valid\\n\"\n",
    "    M = np.zeros((3,3), dtype = int)\n",
    "    for i in zip(y_test, y_predict):\n",
    "        t1, t2 = i\n",
    "        if i[0] == -1:\n",
    "            t1 = 2\n",
    "        if i[1] == -1:\n",
    "            t2 = 2\n",
    "        M[t1, t2] += 1\n",
    "    text += str(M[0,0])+','+str(M[0,1])+','+str(M[0,2])+'\\n'\n",
    "    text += str(M[1,0])+','+str(M[1,1])+','+str(M[1,2])+'\\n'\n",
    "    text += str(M[2,0])+','+str(M[2,1])+','+str(M[2,2])+'\\n'\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Случайное распределение с той же статистикой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LOG_random = \"\"\n",
    "for e in tqdm(range(50)):\n",
    "    X_train, X_test = getTrainTest(seed = e)\n",
    "    y_test = list(X_test['label'])\n",
    "    random.seed(e)\n",
    "    y_predict = random.sample([0]*y_test.count(0)+[1]*y_test.count(1)+[-1]*y_test.count(-1),len(y_test))\n",
    "    LOG_random+=make_log(y_test, y_predict, seed=e)\n",
    "open('logs/Randomlogs.txt','w+').write(LOG_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Нулевое распределение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LOG_zero = \"\"\n",
    "for e in tqdm(range(1)):\n",
    "    X_train, X_test = getTrainTest(seed = e)\n",
    "    y_test = list(X_test['label'])\n",
    "    random.seed(e)\n",
    "    y_predict = random.sample([0]*len(y_test), len(y_test))\n",
    "    LOG_zero+=make_log(y_test=y_test, y_predict=y_predict, seed=e)\n",
    "open('logs/Zerologs.txt','w+').write(LOG_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "# parsing data\n",
    "##############################\n",
    "def decode(a, encoding=\"utf8\"):\n",
    "    if isinstance(a, bytes):\n",
    "        return a.decode(encoding)\n",
    "    else:\n",
    "        return a\n",
    "\n",
    "    return [decode(i) for i in tokens]\n",
    "\n",
    "def tokenize_me(file_text):\n",
    "    smiles = re.findall(emoji.get_emoji_regexp(), file_text)\n",
    "    for w in smiles:\n",
    "        file_text.replace(w,' ')\n",
    "        \n",
    "    tokens = nltk.word_tokenize(file_text, language='english')\n",
    "\n",
    "    tokens = [i for i in tokens if ( i not in string.punctuation )]\n",
    "    stop_words = stopwords.words('russian')\n",
    "    stop_words.extend(['что', 'это', 'так', 'вот', 'быть', 'как', 'в', '—', 'к', 'на'])\n",
    "    tokens = [stemmer.stem(i) for i in tokens if ( i not in stop_words )]+smiles\n",
    "\n",
    "    tokens = [i.replace(u\"«\", u\"\").replace(u\"»\", u\"\") for i in tokens]\n",
    "    return tokens\n",
    "\n",
    "def get_words_matrix(df):\n",
    "    all_words = []\n",
    "    for i in tqdm(df['data'].get_values()):\n",
    "        words = []\n",
    "        words = tokenize_me(decode(i).lower())\n",
    "        all_words.extend(words)   \n",
    "    all_words = Counter(all_words)\n",
    "    all_words = dict(filter(lambda x:x[1]>1 and x[1]<250, all_words.items()))\n",
    "    print(\"Len: \"+str(len(all_words)))\n",
    "    return list(all_words.keys())\n",
    "\n",
    "def get_X_matrix(df, all_words, show_progress = False, dtype = 1):\n",
    "    X_train = np.zeros((len(df), len(all_words)))\n",
    "    for c,i in tqdm(enumerate(df['data'].get_values())):\n",
    "        words = []\n",
    "        words = tokenize_me(decode(i).lower())\n",
    "        for w in words:\n",
    "            if w in all_words:\n",
    "                ind = all_words.index(w)\n",
    "                X_train[c, ind] += 1\n",
    "    return X_train      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import warnings                        #Костыль\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def get_label(lst):\n",
    "    ind = lst.argmax()\n",
    "    if ind == 0:\n",
    "        return 0\n",
    "    elif ind == 1:\n",
    "        return 1\n",
    "    elif ind == 2:\n",
    "        return -1\n",
    "    \n",
    "def NN(X_train, y_train, X_test, y_test, verbose = 0, epochs = 50):\n",
    "\tN_out = 3\n",
    "\tN_in  = X_train.shape[1]\n",
    "\tX_all = np.concatenate((X_train,X_test))\n",
    "\ty_all = keras.utils.to_categorical(np.concatenate((y_train,y_test)), num_classes=N_out)\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(512, activation='relu', input_dim=N_in))\n",
    "# \tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "# \tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(N_out, activation='softmax'))\n",
    "\tsgd = SGD(lr=0.01, decay=1e-6, momentum=0.8, nesterov=True)\n",
    "\tmodel.compile(loss='categorical_crossentropy',\n",
    "\t              optimizer=sgd,\n",
    "\t              metrics=['accuracy'])\n",
    "\n",
    "\t##### Draw model graph\n",
    "# \tfrom keras.utils.vis_utils import plot_model  \n",
    "# \tplot_model(model, to_file='model.png', show_shapes=True)  \n",
    "\t######################\n",
    "\n",
    "\n",
    "\thistory = model.fit(X_all,\n",
    "\t \t \t\t \t \ty_all, \n",
    "\t \t \t \t \t \tvalidation_split = 0.3,\n",
    "\t \t \t \t \t \tepochs=epochs,\n",
    "\t \t \t \t \t \tbatch_size=64,\n",
    "\t \t \t \t \t \tverbose=verbose,\n",
    "\t \t \t \t \t \tshuffle=False)\n",
    "\tprint('===')  \n",
    "\ty_predict = [get_label(k) for k in model.predict(X_test, batch_size=32, verbose=0)]\n",
    "\treturn y_predict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LogisticRegressionScore(X_train, y_train, X_test, y_test):\n",
    "    regr = LogisticRegression(C = 0.4)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_predict = regr.predict(X_test)\n",
    "    temp = make_log(y_predict, y_test)\n",
    "    return temp\n",
    "def SVMScore(X_train, y_train, X_test, y_test):\n",
    "    SVM_model = LinearSVC(C = 0.05)\n",
    "    SVM_model.fit(X_train, y_train)\n",
    "    y_predict = SVM_model.predict(X_test)\n",
    "    temp = make_log(y_predict, y_test)\n",
    "    return temp\n",
    "\n",
    "def NNScore(X_train, y_train, X_test, y_test, verbose = 1, epochs = 10):\n",
    "    y_predict = NN(X_train, y_train, X_test, y_test, verbose = verbose, epochs=epochs)\n",
    "    temp = make_log(y_predict, y_test)\n",
    "    return temp\n",
    "\n",
    "def LR_SVM_NN_logs(X_train, y_train, X_test, y_test):\n",
    "    return (LogisticRegressionScore(X_train, y_train, X_test, y_test), \n",
    "            SVMScore(X_train, y_train, X_test, y_test), \n",
    "            NNScore(X_train, y_train, X_test, y_test)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVM_log    = \"\"\n",
    "LOGREG_log = \"\"\n",
    "NN_log     = \"\"\n",
    "for e in range(100):\n",
    "    df_train, df_test  = getTrainTest(seed = e)\n",
    "    dtype = 2\n",
    "    all_words = get_words_matrix(df_train)\n",
    "    print('Train')\n",
    "    X_train = get_X_matrix(df_train, all_words, show_progress = True)\n",
    "    print('Test')\n",
    "    X_test  = get_X_matrix(df_test, all_words, show_progress = True)\n",
    "    y_train = df_train['label']\n",
    "    y_test  = df_test['label']\n",
    "    \n",
    "    print('LogReg')\n",
    "    LOGREG_log += LogisticRegressionScore(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    print(\"SVM\")\n",
    "    SVM_log += SVMScore(X_train, y_train, X_test, y_test)\n",
    "    NN_log += NNScore(X_train, y_train, X_test, y_test, verbose=0, epochs=13)\n",
    "\n",
    "    open('logs/LogReglogs.txt','w+').write(LOGREG_log)\n",
    "    open('logs/SVMlogs.txt','w+').write(SVM_log)\n",
    "    open('logs/NNlogs.txt','w+').write(NN_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
